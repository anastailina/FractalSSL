{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6625b22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ts2vec\n",
      "  Downloading ts2vec-0.1-py3-none-any.whl.metadata (53 bytes)\n",
      "Downloading ts2vec-0.1-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: ts2vec\n",
      "Successfully installed ts2vec-0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install ts2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32303478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pamap2_ts2vec_fractal_ssl.py\n",
    "\"\"\"End‑to‑end pipeline for\n",
    "1. Loading PAMAP2 patient sensor data\n",
    "2. Pre‑training a TS2Vec encoder\n",
    "3. Training a Fractal‑SSL model that wraps TS2Vec as the backbone\n",
    "\n",
    "The script is organised so that each stage can be run independently from the\n",
    "command line:\n",
    "\n",
    "    # Step 0 – install deps (create a fresh Python 3.10 venv first!)\n",
    "    pip install -r requirements.txt\n",
    "\n",
    "    # Step 1 – cache cleaned windows & basic stats (runs quickly)\n",
    "    python pamap2_ts2vec_fractal_ssl.py prepare \\\n",
    "        --data-root /path/to/PAMAP2_Dataset \\\n",
    "        --out-dir cache/\n",
    "\n",
    "    # Step 2 – contrastive pre‑train TS2Vec backbone\n",
    "    python pamap2_ts2vec_fractal_ssl.py ts2vec-pretrain \\\n",
    "        --cache-dir cache/ \\\n",
    "        --epochs 50 --batch-size 256 --gpu 0\n",
    "\n",
    "    # Step 3 – Fractal‑SSL fine‑tuning (hierarchical multi‑scale objective)\n",
    "    python pamap2_ts2vec_fractal_ssl.py fractal-ssl \\\n",
    "        --cache-dir cache/ \\\n",
    "        --epochs 100 --batch-size 128 --gpu 0\n",
    "\n",
    "    # Step 4 – evaluate on downstream activity‑recognition task (linear probe)\n",
    "    python pamap2_ts2vec_fractal_ssl.py evaluate \\\n",
    "        --cache-dir cache/ \\\n",
    "        --checkpoint runs/fractal_ssl_best.ckpt\n",
    "\n",
    "Notes\n",
    "-----\n",
    "* The script intentionally keeps all heavy‑lifting (datasets, models, loss\n",
    "  functions) in‑file so you can experiment without hunting across packages.\n",
    "* Replace `/path/to/PAMAP2_Dataset` with wherever you unzipped\n",
    "  `PAMAP2_Dataset.zip`.\n",
    "* Requires a GPU (tested on RTX 4090 w/ 24 GiB VRAM). CPU will work but it’s\n",
    "  slow.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List, Dict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    # pip install ts2vec (official impl) OR copy repo to PYTHONPATH\n",
    "    from ts2vec import TS2Vec\n",
    "except ImportError as e:\n",
    "    raise SystemExit(\"TS2Vec not found. Run `pip install git+https://github.com/zhihanyue/ts2vec.git` first.\") from e\n",
    "\n",
    "# -------------------------\n",
    "# Utility helpers\n",
    "# -------------------------\n",
    "\n",
    "def sliding_window(a: np.ndarray, win_size: int, step: int = 1) -> np.ndarray:\n",
    "    \"\"\"Return views of `a` with shape (n_windows, win_size, n_features).\"\"\"\n",
    "    n_samples, n_feat = a.shape\n",
    "    if win_size > n_samples:\n",
    "        raise ValueError(\"win_size larger than input length\")\n",
    "    n_windows = 1 + (n_samples - win_size) // step\n",
    "    stride0, stride1 = a.strides\n",
    "    return np.lib.stride_tricks.as_strided(\n",
    "        a,\n",
    "        shape=(n_windows, win_size, n_feat),\n",
    "        strides=(step * stride0, stride0, stride1),\n",
    "        writeable=False,\n",
    "    )\n",
    "\n",
    "# -------------------------\n",
    "# 0. Dataset preparation\n",
    "# -------------------------\n",
    "\n",
    "SENSOR_COLS = list(range(3, 54))  # cols 3‑53 in original file (0‑index)\n",
    "LABEL_COL = 1  # activityID\n",
    "TIMESTAMP_COL = 0\n",
    "\n",
    "class Pamap2WindowDataset(Dataset):\n",
    "    \"\"\"Pre‑processed sliding windows for SSL + downstream tasks.\"\"\"\n",
    "\n",
    "    def __init__(self, cache_npz: Path):\n",
    "        self.data = np.load(cache_npz, allow_pickle=True)\n",
    "        self.x: np.ndarray = self.data[\"x\"]  # (N, T, C)\n",
    "        self.y: np.ndarray = self.data[\"y\"]  # (N,) – activity label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.x[idx]).float(), torch.tensor(self.y[idx]).long()\n",
    "\n",
    "\n",
    "def prepare(args):\n",
    "    \"\"\"Convert raw .dat files into normalised sliding‑window tensors saved to NPZ.\"\"\"\n",
    "    data_root = Path(args.data_root)\n",
    "    out_dir = Path(args.out_dir)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Hyper‑params\n",
    "    win_size = 400  # 4 s @100 Hz, matches many HAR papers\n",
    "    step = 200      # 50 % overlap\n",
    "\n",
    "    all_windows: List[np.ndarray] = []\n",
    "    all_labels: List[np.ndarray] = []\n",
    "\n",
    "    for dat in sorted(data_root.glob(\"*.dat\")):\n",
    "        print(f\"Parsing {dat.name}…\")\n",
    "        df = pd.read_csv(dat, sep=\" \", header=None)\n",
    "        # Keep only sensor + label\n",
    "        sensors = df.iloc[:, SENSOR_COLS].replace({\"NaN\": np.nan}).astype(float)\n",
    "        labels = df.iloc[:, LABEL_COL].astype(int)\n",
    "        # Drop rows with any NaNs, reset index for contiguous windows\n",
    "        good = sensors.dropna().reset_index(drop=True)\n",
    "        lbl = labels.loc[good.index].reset_index(drop=True)\n",
    "        x = good.to_numpy(dtype=np.float32)\n",
    "        # Standardise per‑sensor globally (fit across file)\n",
    "        mu = x.mean(axis=0)\n",
    "        sigma = x.std(axis=0) + 1e-6\n",
    "        x = (x - mu) / sigma\n",
    "        windows = sliding_window(x, win_size, step)\n",
    "        y_windows = sliding_window(lbl.to_numpy(), win_size, step)[:, 0]  # majority vote later\n",
    "        all_windows.append(windows)\n",
    "        all_labels.append(y_windows)\n",
    "\n",
    "    X = np.concatenate(all_windows, axis=0)\n",
    "    y = np.concatenate(all_labels, axis=0)\n",
    "    assert X.shape[0] == y.shape[0]\n",
    "\n",
    "    # Majority activity in each window\n",
    "    from scipy import stats\n",
    "    y_mode = stats.mode(y, axis=1, keepdims=False)[0]\n",
    "\n",
    "    np.savez_compressed(out_dir / \"pamap2_windows.npz\", x=X, y=y_mode)\n",
    "    print(f\"Saved {X.shape[0]} windows → {out_dir/'pamap2_windows.npz'}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a622ff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------\n",
    "# 1. TS2Vec backbone\n",
    "# -------------------------\n",
    "\n",
    "def ts2vec_pretrain(args):\n",
    "    cache_npz = Path(args.cache_dir) / \"pamap2_windows.npz\"\n",
    "    dset = Pamap2WindowDataset(cache_npz)\n",
    "    loader = DataLoader(dset, batch_size=args.batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
    "\n",
    "    device = torch.device(f\"cuda:{args.gpu}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = TS2Vec(\n",
    "        input_dims=dset.x.shape[-1],\n",
    "        device=device,\n",
    "        repr_dims=args.repr_dims,\n",
    "    )\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        epoch_loss = 0.0\n",
    "        for batch, _ in loader:\n",
    "            batch = batch.to(device)\n",
    "            loss = model(batch)\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            epoch_loss += loss.item() * len(batch)\n",
    "        print(f\"[TS2Vec] epoch {epoch:03d}/{args.epochs} – loss {epoch_loss/len(dset):.4f}\")\n",
    "        if epoch % 10 == 0:\n",
    "            ckpt = f\"runs/ts2vec_epoch{epoch}.pt\"\n",
    "            Path(\"runs\").mkdir(exist_ok=True)\n",
    "            torch.save(model.state_dict(), ckpt)\n",
    "\n",
    "    torch.save(model.state_dict(), \"runs/ts2vec_final.pt\")\n",
    "\n",
    "# -------------------------\n",
    "# 2. Fractal‑SSL wrapper\n",
    "# -------------------------\n",
    "\n",
    "class FractalViewGenerator:\n",
    "    \"\"\"Generates K self‑similar sub‑sequences of exponentially decaying lengths.\n",
    "\n",
    "    Example: given a window length L=400 and levels=4 →\n",
    "        lens = [400, 200, 100, 50]\n",
    "    Each level gets two augmentations (jitter + scaling) to form positives.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, levels: int = 4):\n",
    "        self.levels = levels\n",
    "\n",
    "    def __call__(self, x: torch.Tensor) -> List[torch.Tensor]:\n",
    "        # x: (B, T, C)\n",
    "        B, T, C = x.shape\n",
    "        views = []\n",
    "        for l in range(self.levels):\n",
    "            seg_len = T // (2 ** l)\n",
    "            start = torch.randint(0, T - seg_len + 1, (B,))\n",
    "            for b in range(B):\n",
    "                seg = x[b, start[b]: start[b] + seg_len]\n",
    "                # simple jitter noise aug\n",
    "                seg = seg + 0.01 * torch.randn_like(seg)\n",
    "                views.append(seg)\n",
    "        return views  # length B*levels\n",
    "\n",
    "class FractalSSL(nn.Module):\n",
    "    \"\"\"Fractal self‑supervised learner with TS2Vec backbone + projection head.\"\"\"\n",
    "\n",
    "    def __init__(self, backbone: TS2Vec, proj_dim: int = 128, temp: float = 0.2):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Linear(backbone.repr_dims, proj_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(proj_dim, proj_dim),\n",
    "        )\n",
    "        self.temp = temp\n",
    "        self.view_gen = FractalViewGenerator()\n",
    "\n",
    "    def info_nce(self, z1: torch.Tensor, z2: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute pairwise InfoNCE loss between two view batches.\"\"\"\n",
    "        z1 = nn.functional.normalize(z1, dim=-1)\n",
    "        z2 = nn.functional.normalize(z2, dim=-1)\n",
    "        sim = (z1 @ z2.T) / self.temp  # (B, B)\n",
    "        labels = torch.arange(z1.size(0), device=z1.device)\n",
    "        return nn.functional.cross_entropy(sim, labels)\n",
    "\n",
    "    def forward(self, batch: torch.Tensor) -> torch.Tensor:\n",
    "        views = self.view_gen(batch)  # len = B*levels\n",
    "        losses = []\n",
    "        B = batch.size(0)\n",
    "        for l in range(0, len(views), B):\n",
    "            v = torch.stack(views[l: l + B])  # (B, t_l, C)\n",
    "            # TS2Vec enc expects (B, T, C): pad shorter sequences to max len\n",
    "            padded = nn.utils.rnn.pad_sequence(v, batch_first=True)\n",
    "            z = self.backbone.encode(padded)  # (B, T', D)\n",
    "            # Aggregate by max‑pool across time axis\n",
    "            z = torch.max(z, dim=1).values  # (B, D)\n",
    "            z = self.proj(z)\n",
    "            # positive pairs: current level vs full‑length level 0\n",
    "            if l == 0:\n",
    "                z_full = z  # save for later\n",
    "            else:\n",
    "                losses.append(self.info_nce(z, z_full))\n",
    "        return torch.stack(losses).mean()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddaae347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fractal_ssl(args):\n",
    "    cache_npz = Path(args.cache_dir) / \"pamap2_windows.npz\"\n",
    "    dset = Pamap2WindowDataset(cache_npz)\n",
    "    loader = DataLoader(dset, batch_size=args.batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
    "\n",
    "    device = torch.device(f\"cuda:{args.gpu}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    backbone = TS2Vec(input_dims=dset.x.shape[-1], device=device, repr_dims=args.repr_dims)\n",
    "    model = FractalSSL(backbone).to(device)\n",
    "\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        total = 0.0\n",
    "        for batch, _ in loader:\n",
    "            batch = batch.to(device)\n",
    "            loss = model(batch)\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            total += loss.item() * len(batch)\n",
    "        print(f\"[Fractal‑SSL] epoch {epoch:03d}/{args.epochs} – loss {total/len(dset):.4f}\")\n",
    "        if epoch % 20 == 0:\n",
    "            Path(\"runs\").mkdir(exist_ok=True)\n",
    "            torch.save(model.state_dict(), f\"runs/fractal_ssl_epoch{epoch}.ckpt\")\n",
    "\n",
    "    torch.save(model.state_dict(), \"runs/fractal_ssl_best.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c5b99c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 3. Downstream linear probe\n",
    "# -------------------------\n",
    "\n",
    "def evaluate(args):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import accuracy_score, classification_report\n",
    "    cache_npz = Path(args.cache_dir) / \"pamap2_windows.npz\"\n",
    "    dset = Pamap2WindowDataset(cache_npz)\n",
    "    X = torch.from_numpy(dset.x).float()  # (N, T, C)\n",
    "    y = dset.y\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    backbone = TS2Vec(input_dims=dset.x.shape[-1], device=device)\n",
    "    ckpt = torch.load(args.checkpoint, map_location=device)\n",
    "    backbone.load_state_dict({k.replace(\"backbone.\", \"\"): v for k, v in ckpt.items() if k.startswith(\"backbone.\")})\n",
    "    backbone.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        feats = backbone.encode(X.to(device)).max(dim=1).values.cpu().numpy()\n",
    "\n",
    "    # Simple train/test split\n",
    "    n = len(feats)\n",
    "    idx = np.random.permutation(n)\n",
    "    train_idx, test_idx = idx[: int(0.8 * n)], idx[int(0.8 * n):]\n",
    "    clf = LogisticRegression(max_iter=1000, n_jobs=-1)\n",
    "    clf.fit(feats[train_idx], y[train_idx])\n",
    "    y_pred = clf.predict(feats[test_idx])\n",
    "    acc = accuracy_score(y[test_idx], y_pred)\n",
    "    print(f\"Linear‑probe accuracy: {acc*100:.2f}%\")\n",
    "    print(classification_report(y[test_idx], y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c558cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813264d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 4. CLI entry\n",
    "# -------------------------\n",
    "\n",
    "def build_parser() -> argparse.ArgumentParser:\n",
    "    p = argparse.ArgumentParser(description=\"PAMAP2 × TS2Vec × Fractal‑SSL\")\n",
    "    sub = p.add_subparsers(dest=\"cmd\", required=True)\n",
    "\n",
    "    sp = sub.add_parser(\"prepare\")\n",
    "    sp.add_argument(\"--data-root\", required=True)\n",
    "    sp.add_argument(\"--out-dir\", default=\"cache\")\n",
    "\n",
    "    sp = sub.add_parser(\"ts2vec-pretrain\")\n",
    "    sp.add_argument(\"--cache-dir\", default=\"cache\")\n",
    "    sp.add_argument(\"--epochs\", type=int, default=50)\n",
    "    sp.add_argument(\"--batch-size\", type=int, default=256)\n",
    "    sp.add_argument(\"--repr-dims\", type=int, default=320)\n",
    "    sp.add_argument(\"--gpu\", type=int, default=0)\n",
    "\n",
    "    sp = sub.add_parser(\"fractal-ssl\")\n",
    "    sp.add_argument(\"--cache-dir\", default=\"cache\")\n",
    "    sp.add_argument(\"--epochs\", type=int, default=100)\n",
    "    sp.add_argument(\"--batch-size\", type=int, default=128)\n",
    "    sp.add_argument(\"--repr-dims\", type=int, default=320)\n",
    "    sp.add_argument(\"--gpu\", type=int, default=0)\n",
    "\n",
    "    sp = sub.add_parser(\"evaluate\")\n",
    "    sp.add_argument(\"--cache-dir\", default=\"cache\")\n",
    "    sp.add_argument(\"--checkpoint\", required=True)\n",
    "\n",
    "    return p\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a09bd5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h]\n",
      "                             {prepare,ts2vec-pretrain,fractal-ssl,evaluate}\n",
      "                             ...\n",
      "ipykernel_launcher.py: error: the following arguments are required: cmd\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "args = build_parser().parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81083981",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    args = build_parser().parse_args()\n",
    "    if args.cmd == \"prepare\":\n",
    "        prepare(args)\n",
    "    elif args.cmd == \"ts2vec-pretrain\":\n",
    "        ts2vec_pretrain(args)\n",
    "    elif args.cmd == \"fractal-ssl\":\n",
    "        train_fractal_ssl(args)\n",
    "    elif args.cmd == \"evaluate\":\n",
    "        evaluate(args)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ledd_calculation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
